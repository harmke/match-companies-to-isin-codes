{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match company names to ISIN codes using Azure AI Language and Wiki data\n",
    "\n",
    "Entity linking is a natural language processing task that involves identifying and disambiguating entities in a text. Entities are words or phrases that refer to real-world objects, such as people, places, organizations, events, products, etc. Disambiguating entities means resolving the ambiguity that arises when the same word or phrase can refer to different entities, depending on the context. For example, the word \"Apple\" can refer to the fruit, the company, or the Beatles' record label, depending on the text.\n",
    "\n",
    "Entity linking is important for many applications, such as information extraction, knowledge graph construction, question answering, text summarization, and sentiment analysis. By linking entities to their unique identifiers in a knowledge base, such as Wiki data, we can enrich the text with additional information and enable semantic search and reasoning.\n",
    "\n",
    "This example notebook uses the Azure AI Language service and Wiki data to link company names mentioned in unstructured text (e.g. news articles or transcriptions of earning calls) to company ids (ISIN codes). \n",
    "\n",
    "The notebook is divided into the following sections:\n",
    "\n",
    "- Import libraries\n",
    "- Util functions\n",
    "- Get ISIN codes from list of wikipedia pages\n",
    "- Get linked entities from text using Azure AI Language\n",
    "- Function to get ISIN codes from text\n",
    "- Get ISIN codes for each document in `data` folder\n",
    "\n",
    "Please refer to this page for more information on the Azure AI Language entity linking capabilities: https://learn.microsoft.com/en-us/azure/ai-services/language-service/entity-linking/quickstart?tabs=windows&pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# %pip install azure-ai-textanalytics==5.2.0\n",
    "# %pip install nltk\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import requests\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "language_key = os.environ.get('LANGUAGE_KEY')\n",
    "language_endpoint = os.environ.get('LANGUAGE_ENDPOINT')\n",
    "\n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(language_key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=language_endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isin(wikipedia_name):\n",
    "    redirects = check_redirects(wikipedia_name)\n",
    "    if redirects is not None:\n",
    "        wikipedia_name = redirects\n",
    "    try:\n",
    "        url = f\"https://www.wikidata.org/w/api.php?action=wbgetentities&sites=enwiki&props=claims&titles={wikipedia_name}&format=json\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        entity_id = next(iter(data[\"entities\"]))\n",
    "        value = data[\"entities\"][entity_id]['claims']['P946'][0]['mainsnak'][\"datavalue\"][\"value\"]\n",
    "        return value\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_redirects(titles):\n",
    "    url = f\"https://en.wikipedia.org/w/api.php?action=query&format=json&titles={titles}&redirects\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if \"query\" in data:\n",
    "        if \"redirects\" in data[\"query\"]:\n",
    "            return data[\"query\"][\"redirects\"][0][\"to\"]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ISIN codes from list of wikipedia pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\"Apple_Inc.\", \"Alphabet_Inc.\", \"ASML_Holding\", \"Tesla,_Inc.\", \"Verizon_Communications\"]\n",
    "\n",
    "for company in companies:\n",
    "    print(get_isin(company))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get linked entities from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    documents = [\"\"\"\n",
    "With the upcoming launch of Apple Vision Pro, we're seeing strong excitement in enterprise, leading organizations across many industries, such as Walmart, Nike, Vanguard, Stryker, Bloomberg and SAP started leveraging and investing in Apple Vision Pro as the new platform to bring innovative spatial computing experiences to their customers and employees. \n",
    "\"\"\"]\n",
    "    result = client.recognize_linked_entities(documents = documents)[0]\n",
    "\n",
    "    print(\"Linked Entities:\\n\")\n",
    "    for entity in result.entities:\n",
    "        print(\"\\tName: \", entity.name, \"\\tId: \", entity.data_source_entity_id, \"\\tUrl: \", entity.url)\n",
    "        print(\"\\tMatches:\")\n",
    "        for match in entity.matches:\n",
    "            print(\"\\t\\tText:\", match.text)\n",
    "            print(\"\\t\\tConfidence Score: {0:.2f}\".format(match.confidence_score))\n",
    "        \n",
    "except Exception as err:\n",
    "    print(\"Encountered exception. {}\".format(err))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get ISIN codes from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isin_codes_from_text(client, text):\n",
    "    companies = {}\n",
    "\n",
    "    try:\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            results = client.recognize_linked_entities(documents = [sentence])\n",
    "\n",
    "            for result in results:\n",
    "                for entity in result.entities:\n",
    "                    if entity.data_source_entity_id in companies:\n",
    "                        continue\n",
    "                    isin = get_isin(entity.data_source_entity_id)\n",
    "                    if isin is not None:\n",
    "                        companies.update({entity.data_source_entity_id: isin})\n",
    "                        print(\"\\tId: \", entity.data_source_entity_id, \"\\tUrl: \", entity.url, \"\\tMatches:\", [match.text for match in entity.matches], \"\\tISIN: \", isin)\n",
    "                        \n",
    "        return companies\n",
    "            \n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ISIN codes for each document in data folder\n",
    "\n",
    "Make sure to add any news articles or transcriptions of earning calls to a folder called `data` before running the call below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    with open(file_path, \"r\") as file:\n",
    "        print(filename)\n",
    "        text = file.read()\n",
    "        get_isin_codes_from_text(client, text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
